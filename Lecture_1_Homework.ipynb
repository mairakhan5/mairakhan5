{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mairakhan5/mairakhan5/blob/main/Lecture_1_Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_hEESBoR7Kl",
        "outputId": "1a8836c8-a602-42a2-95cf-763e83872758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ie_EfdmFZ3S219IYN14z8gsc6eAQG4eq\n",
            "To: /content/boston_dataset.csv\n",
            "100%|██████████| 38.7k/38.7k [00:00<00:00, 22.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Mfsyhey7SAhtsPHNHwK6oDGEjIHcudjc\n",
            "To: /content/boston_dataset_clean.csv\n",
            "100%|██████████| 35.7k/35.7k [00:00<00:00, 15.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "#@title Data download\n",
        "#@markdown This cell contains code to retrieve the dataset for our tutorial. You can ignore its contents, for the most part\n",
        "! pip install gdown > /dev/null\n",
        "import gdown\n",
        "\n",
        "def download_gdrive(id_, name):\n",
        "  url = f'https://drive.google.com/uc?id={id_}'\n",
        "  gdown.download(url, name, quiet=False)\n",
        "\n",
        "download_gdrive('1ie_EfdmFZ3S219IYN14z8gsc6eAQG4eq', 'boston_dataset.csv')\n",
        "download_gdrive('1Mfsyhey7SAhtsPHNHwK6oDGEjIHcudjc', 'boston_dataset_clean.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "TaXiS7r4Xw57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework for session 1\n",
        "\n",
        "## The Boston housing dataset\n",
        "\n",
        "In this exercise we will be using the Boston housing datasets, one of the most common reference datasets in introductory data science. The Boston housing dataset contains information about property costs in the Boston area in the 1970s, including data on their location, value, and various features. The dataset includes 506 samples and 14 features, and the task is often used to predict the median value of owner-occupied homes in the area based on variables (_features_, in machine learning parlance) such as the `crim` rate (per capita crime rate by town), the `age` of the property, and the `rm` number of rooms.\n",
        "\n",
        "The features included in the dataset are:\n",
        "\n",
        "   - `crim`: per capita crime rate by town\n",
        "   - `zn`: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "   - `indus`: proportion of non-retail business acres per town\n",
        "   - `chas`: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "   - `nox`: nitrogen oxides concentration (parts per 10 million)\n",
        "   - `rm`: average number of rooms per dwelling\n",
        "   - `age`: proportion of owner-occupied units built prior to 1940\n",
        "   - `dis`: weighted distances to five Boston employment centres\n",
        "   - `rad`: index of accessibility to radial highways\n",
        "   - `tax`: full-value property-tax rate per $10,000\n",
        "   - `ptratio`: pupil-teacher ratio by town\n",
        "   - `b`: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "   - `lstat`: lower status of the population (percent)\n",
        "\n",
        "\n",
        "Finally, the median value of owner-occupied homes in \\$1,000s (e.g. 30 means $30,000) is quoted as `medv`. \n",
        "\n",
        "If you have looked at the features above, you may have (reasonably so) raised your eyebrows at features like `black`. This merits a crucial comment on the development of machine learning models. While this feature may be relevant for understanding housing prices in the Boston area in the 1970s, it is important to consider the potential ethical implications of using it in predictive affairs. Using a feature that represents the racial makeup of a community can (and will) perpetuate existing biases or discriminate against certain groups. Choosing fair and unbiased features is especially important when machine learning systems are embedded in decision-making processes, as they can have real-world consequences for individuals and communities. Thus, exploratory data analysis is not only a crucial step for success -- it is only necessary to make machine learning models that are fair and for the good of everyone involved."
      ],
      "metadata": {
        "id": "vDm49VeOTY_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arranging a dataset\n",
        "\n",
        "We have downloaded a version of the Boston housing dataset with the cell code at the top of the notebook. Please read the contents of this `boston_dataset.csv` file, and have a look at the structure of the DataFrame."
      ],
      "metadata": {
        "id": "zKWQ_EN_WdjP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-SrL6KdVT8cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploratory data analysis\n",
        "\n",
        "Let's do some basic exploratory data analysis. Have a look at the mean values, standard deviations and ranges of the features:"
      ],
      "metadata": {
        "id": "dwHlYI1pW6KV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3TgEJMlfXWQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise the distributions of these variables using a histogram:"
      ],
      "metadata": {
        "id": "beyUl8QdXXRq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JjBuUpL3b9Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you make a plot to study the correlation between different features and the target variable `medv`?"
      ],
      "metadata": {
        "id": "MTFMsrRnb8k6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-z9lT0Y_Yopq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask yourself a few basic questions about the data:\n",
        "\n",
        "- Some features are concentrated in a narrow range. For example, there are many houses with 5-8 rooms, but very few with less than 4 or more than 9 rooms. What is the impact of data availability in our ability to make predictions or extract conclusions? Which other variables exhibit this behaviour?\n",
        "- Some features exhibit clear correlation with the target. For example, higher criminality areas show much lower prices. Can you identify several variables that show this behaviour? Which variables don't seem to have any correlation with the price? Does this mean they are not useful for predictive models, or to draw conclusions?"
      ],
      "metadata": {
        "id": "56fG-yICerx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filling missing values\n",
        "\n",
        "Most real datasets have missing values, and this is not an exception. Count the number of missing entries for each feature."
      ],
      "metadata": {
        "id": "CGzNJaZVZZWP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6bwaHQaco7ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement an imputation strategy that:\n",
        "\n",
        "- for categorical variables, assumes the most common example\n",
        "- for continuous variables, uses the median value (why the median and not the mean?)"
      ],
      "metadata": {
        "id": "DL5DQcmkowO8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fBEOa4FAZ31o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}